<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Huxin's Website</title><meta name="author" content="Huxin Gao (高沪昕)"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Huxin's Website" type="application/atom+xml">
</head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Huxin's Website</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/News"> News</a></li><li class="menus_item"><a class="site-page" href="/Publications"> Publications</a></li><li class="menus_item"><a class="site-page" href="/Projects"> Projects</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/profile.png'" alt="avatar"></div><div class="author-discrip"><h3>Huxin Gao (高沪昕)</h3><p class="author-bio">PhD candidate in NUS.</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https://github.com/ghx-0228" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://www.linkedin.com/feed/?trk=guest_homepage-basic_nav-header-signin" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="E0343967@u.nus.edu" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="https://scholar.google.com/citations?user=-jPDb4AAAAAJ&amp;hl=en&amp;oi=ao" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li><li><a class="e-social-link" href="https://orcid.org/0000-0002-8700-560X" target="_blank"><i class="fab fa-orcid" aria-hidden="true"></i><span>ORCID</span></a></li></ul></div><a class="cv-links" href="/attaches/CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>My Detailed CV</span></i></a><div><p><script id="clustrmaps" type="text/javascript" src="//cdn.clustrmaps.com/map_v2.js?cl=080808&amp;w=170&amp;t=n&amp;d=K29yo_23vu-ZyEMROcuNoQliylui8m6r120220e7y_k&amp;co=ffffff&amp;cmo=3acc3a&amp;cmn=ff5353&amp;ct=808080"></script></p></div></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">Publications</h2><article><h2 id="Journal"><a href="#Journal" class="headerlink" title="Journal"></a>Journal</h2><div style="text-align:justify">
<img src='/img/FSSL.png' align=right width=350px />

<p>[8] L. Qiu, J. Cheng, <strong>H. Gao</strong>, W. Xiong, and H. Ren, “Federated semi-supervised learning for medical image segmentation via pseudo-label denoising,” <strong>IEEE Journal of Biomedical and Health Informatics (JBHI)</strong>, 2023.</p>
<p>In this work, I help conduct experiments to verify the proposed FSSL model and modify the manuscript.</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/10121665"> Paper</a></p>
</div>
<div style="text-align:justify">
<img src='/img/SAVAnet.png' align=right width=350px />

<p>[7] <strong>H. Gao</strong>, W. Fan, L. Qiu, X. Yang, Z. Li, X. Zuo, Y. Li, M.Q.Meng and H. Ren, “SAVAnet: Surgical action-driven visual attention network for autonomous endoscope control,” <strong>IEEE Transactions on Automation Science &amp; Engineering (T-ASE)</strong>, 2022.</p>
<p>In this work, we learnt from the surgeons’ visual attention mechanism and propose a novel network called SAVAnet to predict visual attention with action guidance. Additionally, we implemented the SAVAnet on a da Vinci simulator to execute the autonomous endoscope control. </p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9895213"> Paper</a></p>
</div>
<div style="text-align:justify">
<img src='/img/exvivo_study.png' align=right width=350px />

<p>[6] X. Yang, <strong>H. Gao</strong>, J. Chen, C. Hou, Z. Zhou, R. Ji, H. Liu, H. Ren, Li. Sun, X. Yang, Y. Li and X. Zuo, “Development and primary evaluation of a digestive endoscopy minimally invasive surgical robot system in endoscopic submucosal dissection: an ex vivo, feasibility study,” <strong>Chinese Journal of Digestive Endoscopy</strong>, 2022.</p>
<p>In this work, we preliminarily evaluate the dissection effect, safety and performance of the endoscopic robot system for endoscopic submucosal dissection (ESD) in ex-vivo porcine gastric.</p>
<p>Accepted</p>
</div>

<div style="text-align:justify">
<img src='/img/JACS.png' align=right width=350px />

<p>[5] Z. Yi, <strong>H. Gao</strong>, X. Ji, S.Y. Chong, Y. Mao, B. Luo, C. Shen, S. Han, J.W. Wang, S. Jung, P. Shi, H. Ren and X. Liu, “Mapping drug-induced neuropathy through in-situ motor protein tracking and machine learning,” <strong>Journal of the American Chemical Society</strong> (IF: 14.612), 2021.</p>
<p>In this work, we report dynamic near-infrared upconversion imaging and prove that combining the upconverting nanoplatform with machine learning offers a powerful tool for mapping chemotherapy-induced peripheral neuropathy and assessing drug-induced neurotoxicity.</p>
<p><a target="_blank" rel="noopener" href="https://pubs.acs.org/doi/abs/10.1021/jacs.1c07312"> Paper</a></p>
</div>
<div style="text-align:justify">
<img src='/img/OrigamiOpticalFlow.png' align=right width=350px />

<p>[4] B.S. Yeow, H. Yang, M.S. Kalairaj, <strong>H. Gao</strong>, C.J. Cai, S. Xu, P. Chen and H. Ren, “Magnetically Steerable Serial and Parallel Structures by Mold-Free Origami Templating and Domain Setting,” <strong>Advanced Materials Technologies</strong>, 2021.</p>
<p>In this work, I was in charge of tracking origami motions using optical flow. The developed origami robot “Terapod crawler” can grasp small targets by magnetic actuation. </p>
<p><a target="_blank" rel="noopener" href="https://onlinelibrary.wiley.com/doi/10.1002/admt.202101140">Paper</a></p>
</div>

<div style="text-align:justify">
<img src='/img/NC_hand_control.png' align=right width=350px />

<p>[3] L. Zhang, K.S. Kumar, H. Hao, C. J. Cai, H. He, <strong>H. Gao</strong>, S. Yue, C. Li, R.C. Seet, H. Ren and J. Ouyang, “Fully organic compliant dry electrodes self-adhesive to skin for long-term motion-robust epidermal biopotential monitoring,” <strong>Nature Communication</strong>, 2020.</p>
<p>In this work, I was in charge of the EMG-based control of a robotic hand. The EEG signal from human arm is sampled by the designed sensor, collected to the PC by Arduino in real time to control the robotic hand: open and close. The test validates the perceptive performance of the sensor.</p>
<p><a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41467-020-18503-8"> Paper</a> | <a target="_blank" rel="noopener" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-020-18503-8/MediaObjects/41467_2020_18503_MOESM9_ESM.mp4">Video</a></p>
</div>

<div style="text-align:justify">
<img src='/img/Skullbot.png' align=right width=350px />

<p>[2] X. Xiao, <strong>H. Gao</strong>, C. Li, L. Qiu, K. S. Kumar, C. J. Cai, B. S. Bhola, N. K. K. King and H. Ren, “Portable body-attached positioning mechanism towards robotic needle intervention,” <strong>IEEE/ASME Transactions on Mechatronics</strong>, vol. 25, pp. 1105–1116, April 2020.</p>
<p>We proposed a novel skull-mounted robot, which has the following features: cable-driven, MRI-compatible, 4 DOFs, and parallel structure with RCM mechanism. The open-loop positioning accuracy is within ±1 mm and −0.8&deg; to 1.5&deg;.</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9001218">Paper</a></p>
</div>

<div style="text-align:justify">
<img src='/img/notes.png' align=right width=350px />

<p>[1] C. Li, Y. Yan, X. Xiao, X. Gu, <strong>H. Gao</strong>, X. Duan, X. Zuo, Y. Li and H. Ren, “A miniature manipulator with variable stiffness towards minimally invasive transluminal endoscopic surgery,” <strong>IEEE Robotics and Automation Letters</strong>, 2021.</p>
<p>In this work, I was in charge of the ex-vivo test. The experimental results show that the designed flexible manipulator can finish different motion smoothly inside porcine stomach. </p>
<p>Additionally, I made the presentation for this paper in ICRA2021.</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9384192">Paper</a> | Video (<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV19U4y1G7Ko/">Bilibili</a> or <a target="_blank" rel="noopener" href="https://youtu.be/aklb7nLy7-k">YouTube</a>) | Presentation (<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1K64y1r7KP">Bilibili</a> or <a target="_blank" rel="noopener" href="https://youtu.be/KnV3zb9gjDQ" title="YouTube">YouTube</a>)</p>
</div>

<h2 id="Conference"><a href="#Conference" class="headerlink" title="Conference"></a>Conference</h2><div style="text-align:justify">
<img src='/img/GESRsim.png' align=right width=350px />

<p>[3] <strong>H. Gao</strong>, Z. Zhang, C. Li, X. Xiao, L. Qiu, X. Yang, R. Hao, X. Zuo, Y. Li and H. Ren, “GESRsim: gastrointestinal endoscopic surgical robot simulator,” in 2022 <strong>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</strong>, 2022</p>
<p>In this work, we use CoppeliaSim to develop the first robotic simulator for the GESR system (GESRsim) based on our robotic prototype. The GESRsim provides several 3D models and kinematics of the manipulators and endoscopic snake bone, and scenes for robotic GES training. Besides, we performed teleoperation and implemented advanced control algorithms. </p>
<p>Accepted</p>
</div>

<div style="text-align:justify">
<img src='/img/RCMrecc.png' align=right width=350px />

<p>[2] <strong>H. Gao</strong>, X. Xiao, L. Qiu, M.Q. Meng, N.K.K. King and H. Ren, “Remote-center-of-motion recommendation toward brain needle intervention using deep reinforcement learning,” in 2021 <strong>IEEE International Conference on Robotics and Automation (ICRA)</strong>, 2021.</p>
<p>We proposed to use DRL to recommend an optimal RCM (burr hole or insertion point). In this work, a needle intervention scene is constructed in Vrep for the interaction with RL agent. Additionally, the needle intervention for our designed robot needs to satisfied three defined criteria: one clinical requirements (COA) and two mechanical requirements (MIK, MLM). A reward function is designed to combine the above criteria.</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9560747">Paper</a> | <a target="_blank" rel="noopener" href="https://youtu.be/fgIluKkodns">Video</a> | Presentation (<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1T54y1H7nf">Bilibili</a> or <a target="_blank" rel="noopener" href="https://youtu.be/XJLUaxESNbo" title="YouTube">YouTube</a>)</p>
</div>

<div style="text-align:justify">
<img src='/img/magnatic_connected_robot.png' align=right width=350px />

<p>[1] X. Xiao, S. Xu, C. Li, X. Gu, <strong>H Gao</strong>, M.Q.Meng and H. Ren, “Magnetically-connected modular reconfigurable mini-robotic system with bilateral isokinematic mapping and fast on-site assembly towards minimally invasive procedures,” in 2021 <strong>IEEE International Conference on Robotics and Automation (ICRA)</strong>, 2021.</p>
<p>In this work, I was in charge of robotic simulation and assisting in some experiments. </p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9561141">Paper</a> | <a target="_blank" rel="noopener" href="https://youtu.be/ExCoX9qYcGw">Video</a></p>
</div>

<h2 id="Workshop"><a href="#Workshop" class="headerlink" title="Workshop"></a>Workshop</h2><div style="text-align:justify">
<img src='/img/Wrist.png' align=right width=350px />

<p>[1] <strong>H Gao</strong>, X. Xiao, X. Yang, T. Zhang, X. Zuo, Y. Li and H. Ren, “A miniature 3-DoF flexible parallel robotic wrist using NiTi wires for gastrointestinal endoscopic surgery,” in 2022 <strong>IEEE International Conference on Robotics and Automation (ICRA) workshop</strong> – Frontiers of Endoluminal Intervention: Clinical opportunities and technical challenges, 2022.</p>
<p>In this work, we propose a miniature 3-DoF flexible parallel robotic wrist. Additionally, we validate the performance in an ex-vivo test.</p>
</div>

<h2 id="Patent"><a href="#Patent" class="headerlink" title="Patent"></a>Patent</h2><p>[3] A measuring device and a measuring method to positioning repeatability and dynamic response for the miniature robotic arm. (Chinese patent, filed)</p>
<p>[2] A scoring method and a scoring device of fully automatic abdominal wall withdrawal reflex. (Chinese patent, filed)</p>
<p>[1] A soft robot and control strategy for the movement of the concentric tubes. (Chinese patent, filed)</p>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/News"> News</a></li><li class="nav_item"><a class="nav-page" href="/Publications"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/Projects"> Projects</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2023 by Huxin Gao (高沪昕)</div><div class="theme-info">Powered by <a target="_blank" href="https://hexo.io" rel="nofollow noopener">Hexo</a> & <a target="_blank" href="https://github.com/PhosphorW/hexo-theme-academia" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>